{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=datasets.MNIST(\"\", train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=datasets.MNIST(\"\", train=False,download=True,transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset=torch.utils.data.DataLoader(test,batch_size=10,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 4, 1, 3, 6, 8, 8, 5, 7, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 1, 3, 6, 8, 8, 5, 7, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x233bc71c208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[9].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "counter_dict={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset:\n",
    "    Xs,ys=data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)]+=1\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/counter*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(28*28,64)\n",
    "        self.fc2=nn.Linear(64,64)\n",
    "        self.fc3=nn.Linear(64,64)\n",
    "        self.fc4=nn.Linear(64,10)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "net=Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3620, 0.0098, 0.5611, 0.4721, 0.1392, 0.7064, 0.8059, 0.2738, 0.4104,\n",
       "         0.3936, 0.2997, 0.9011, 0.7546, 0.6687, 0.0923, 0.8290, 0.6934, 0.7875,\n",
       "         0.3536, 0.8298, 0.6627, 0.1092, 0.4630, 0.3401, 0.5437, 0.5676, 0.7327,\n",
       "         0.0096],\n",
       "        [0.1955, 0.9676, 0.7734, 0.1303, 0.1963, 0.7347, 0.9102, 0.0886, 0.5219,\n",
       "         0.4035, 0.8070, 0.9409, 0.1755, 0.7418, 0.1255, 0.8157, 0.4155, 0.4301,\n",
       "         0.6896, 0.5425, 0.0471, 0.9481, 0.9414, 0.8787, 0.8934, 0.1585, 0.3734,\n",
       "         0.0587],\n",
       "        [0.4752, 0.4921, 0.0144, 0.4557, 0.8686, 0.5401, 0.9935, 0.7792, 0.1073,\n",
       "         0.0173, 0.7065, 0.3925, 0.2987, 0.1440, 0.2232, 0.7046, 0.5702, 0.5702,\n",
       "         0.0493, 0.5043, 0.5801, 0.6980, 0.4427, 0.3476, 0.4607, 0.7330, 0.8811,\n",
       "         0.0980],\n",
       "        [0.7450, 0.1367, 0.6133, 0.1508, 0.6510, 0.5400, 0.0166, 0.0634, 0.1455,\n",
       "         0.5914, 0.9652, 0.1787, 0.4294, 0.8656, 0.0650, 0.0028, 0.8163, 0.0583,\n",
       "         0.0910, 0.0799, 0.7042, 0.1218, 0.0473, 0.1588, 0.9517, 0.8418, 0.3854,\n",
       "         0.5515],\n",
       "        [0.2505, 0.5902, 0.9674, 0.1607, 0.9853, 0.7188, 0.0499, 0.5144, 0.8803,\n",
       "         0.9948, 0.4097, 0.1689, 0.6209, 0.4609, 0.9967, 0.2617, 0.2100, 0.8001,\n",
       "         0.8433, 0.1984, 0.4644, 0.0738, 0.3514, 0.8134, 0.8976, 0.2117, 0.8892,\n",
       "         0.2293],\n",
       "        [0.2879, 0.7061, 0.0820, 0.9780, 0.2912, 0.9036, 0.7579, 0.4457, 0.7740,\n",
       "         0.9402, 0.6691, 0.2680, 0.7007, 0.1387, 0.6557, 0.3301, 0.0813, 0.5649,\n",
       "         0.5548, 0.1930, 0.6933, 0.3538, 0.2576, 0.2507, 0.1779, 0.0654, 0.8974,\n",
       "         0.1934],\n",
       "        [0.1306, 0.2617, 0.1025, 0.3671, 0.9447, 0.3747, 0.7789, 0.1963, 0.7649,\n",
       "         0.3412, 0.3262, 0.9727, 0.8576, 0.7417, 0.2591, 0.1954, 0.9082, 0.8029,\n",
       "         0.8191, 0.4220, 0.8891, 0.7049, 0.6053, 0.0853, 0.1609, 0.0585, 0.7715,\n",
       "         0.4134],\n",
       "        [0.3731, 0.2725, 0.5460, 0.3779, 0.5492, 0.6258, 0.5813, 0.9116, 0.9746,\n",
       "         0.1420, 0.3912, 0.2652, 0.2410, 0.6614, 0.5569, 0.2401, 0.9684, 0.3456,\n",
       "         0.3480, 0.7369, 0.0793, 0.7966, 0.9055, 0.1375, 0.2120, 0.3877, 0.5698,\n",
       "         0.0354],\n",
       "        [0.1936, 0.9801, 0.5576, 0.5059, 0.2983, 0.8578, 0.1211, 0.2582, 0.8564,\n",
       "         0.8975, 0.3660, 0.2622, 0.1188, 0.3630, 0.6868, 0.8909, 0.7874, 0.6646,\n",
       "         0.6672, 0.5463, 0.5128, 0.9397, 0.7535, 0.0853, 0.5676, 0.0730, 0.0774,\n",
       "         0.2416],\n",
       "        [0.8656, 0.9856, 0.3124, 0.2822, 0.3031, 0.5938, 0.9357, 0.0382, 0.2694,\n",
       "         0.2078, 0.5033, 0.2161, 0.2184, 0.6944, 0.2302, 0.3905, 0.8335, 0.8268,\n",
       "         0.9520, 0.7495, 0.7773, 0.0965, 0.5938, 0.8103, 0.0574, 0.2904, 0.1545,\n",
       "         0.4072],\n",
       "        [0.3865, 0.9763, 0.5493, 0.7260, 0.2320, 0.0314, 0.1328, 0.4582, 0.5296,\n",
       "         0.6167, 0.6657, 0.5751, 0.7975, 0.6479, 0.8769, 0.6777, 0.2602, 0.6557,\n",
       "         0.1386, 0.4740, 0.2295, 0.6217, 0.6865, 0.0991, 0.7374, 0.7961, 0.0063,\n",
       "         0.6978],\n",
       "        [0.3940, 0.3031, 0.8741, 0.8203, 0.9702, 0.1957, 0.4667, 0.6582, 0.2114,\n",
       "         0.8623, 0.4468, 0.9576, 0.7626, 0.4060, 0.6673, 0.7881, 0.2794, 0.4219,\n",
       "         0.2915, 0.3332, 0.7394, 0.0048, 0.9181, 0.9826, 0.6045, 0.5186, 0.3042,\n",
       "         0.2134],\n",
       "        [0.6780, 0.6807, 0.5786, 0.0305, 0.5470, 0.4785, 0.1658, 0.7808, 0.1341,\n",
       "         0.0117, 0.2973, 0.8797, 0.7552, 0.5337, 0.5042, 0.8951, 0.5322, 0.4560,\n",
       "         0.4626, 0.0615, 0.3070, 0.3367, 0.7141, 0.3229, 0.3353, 0.9145, 0.5409,\n",
       "         0.3077],\n",
       "        [0.3031, 0.6699, 0.8427, 0.1989, 0.6441, 0.8539, 0.7943, 0.4439, 0.9785,\n",
       "         0.0957, 0.2739, 0.2677, 0.3591, 0.6272, 0.7093, 0.9747, 0.1937, 0.1805,\n",
       "         0.5041, 0.6920, 0.6301, 0.7758, 0.6831, 0.0918, 0.0117, 0.1627, 0.1412,\n",
       "         0.2973],\n",
       "        [0.0702, 0.7949, 0.6853, 0.4855, 0.7739, 0.0486, 0.2216, 0.5199, 0.0103,\n",
       "         0.1060, 0.0012, 0.2514, 0.2438, 0.0352, 0.1519, 0.9893, 0.6758, 0.3538,\n",
       "         0.3135, 0.5567, 0.7499, 0.6377, 0.8295, 0.3730, 0.2515, 0.0018, 0.4293,\n",
       "         0.2900],\n",
       "        [0.9656, 0.5749, 0.6584, 0.8315, 0.1423, 0.6166, 0.2602, 0.4945, 0.6901,\n",
       "         0.8590, 0.6940, 0.9920, 0.9174, 0.2042, 0.2413, 0.8869, 0.7424, 0.3445,\n",
       "         0.7525, 0.4170, 0.9190, 0.4093, 0.2208, 0.8758, 0.1948, 0.1500, 0.7478,\n",
       "         0.8355],\n",
       "        [0.2278, 0.4312, 0.7227, 0.8965, 0.8776, 0.1489, 0.4443, 0.6856, 0.1342,\n",
       "         0.4933, 0.5416, 0.4160, 0.7145, 0.9977, 0.4165, 0.1738, 0.0525, 0.7134,\n",
       "         0.8127, 0.9181, 0.6215, 0.0966, 0.7478, 0.9062, 0.7680, 0.4125, 0.7529,\n",
       "         0.1946],\n",
       "        [0.7808, 0.8825, 0.4374, 0.9946, 0.2476, 0.9736, 0.2555, 0.3851, 0.3059,\n",
       "         0.8700, 0.9425, 0.6126, 0.1638, 0.6542, 0.7905, 0.2864, 0.9749, 0.7083,\n",
       "         0.9701, 0.9770, 0.2005, 0.9814, 0.4291, 0.2250, 0.1547, 0.9008, 0.0147,\n",
       "         0.5334],\n",
       "        [0.2895, 0.7573, 0.0725, 0.6844, 0.9778, 0.0859, 0.2927, 0.8803, 0.1845,\n",
       "         0.6803, 0.7630, 0.4812, 0.6265, 0.9692, 0.2290, 0.5644, 0.7312, 0.6292,\n",
       "         0.6379, 0.0616, 0.6763, 0.8923, 0.7719, 0.1103, 0.6561, 0.2006, 0.9036,\n",
       "         0.5371],\n",
       "        [0.2842, 0.7249, 0.3867, 0.1028, 0.7573, 0.1487, 0.2164, 0.8897, 0.8203,\n",
       "         0.8058, 0.6578, 0.6954, 0.8916, 0.7451, 0.4413, 0.6796, 0.6609, 0.0531,\n",
       "         0.6891, 0.2738, 0.7224, 0.3485, 0.6880, 0.8577, 0.3838, 0.8455, 0.4197,\n",
       "         0.3401],\n",
       "        [0.4623, 0.0191, 0.4761, 0.2347, 0.4096, 0.7312, 0.2928, 0.6420, 0.2903,\n",
       "         0.8792, 0.8916, 0.2686, 0.0565, 0.8584, 0.5277, 0.6110, 0.0905, 0.6801,\n",
       "         0.1172, 0.6847, 0.4733, 0.4921, 0.3862, 0.2147, 0.9167, 0.9638, 0.5434,\n",
       "         0.7103],\n",
       "        [0.9740, 0.4129, 0.0104, 0.0297, 0.3781, 0.1932, 0.6406, 0.6401, 0.1875,\n",
       "         0.5882, 0.0123, 0.4891, 0.6468, 0.5260, 0.2698, 0.1227, 0.3081, 0.0821,\n",
       "         0.9094, 0.9549, 0.4768, 0.3061, 0.6679, 0.1117, 0.2609, 0.8031, 0.0529,\n",
       "         0.2197],\n",
       "        [0.2775, 0.1625, 0.0023, 0.4756, 0.1533, 0.5318, 0.9732, 0.3975, 0.1464,\n",
       "         0.6229, 0.1634, 0.2464, 0.1853, 0.3272, 0.4218, 0.9286, 0.1644, 0.2830,\n",
       "         0.6007, 0.9812, 0.1930, 0.6089, 0.5151, 0.6485, 0.8647, 0.3194, 0.1631,\n",
       "         0.1998],\n",
       "        [0.8892, 0.0623, 0.1562, 0.1981, 0.5612, 0.3055, 0.2043, 0.6985, 0.3012,\n",
       "         0.3164, 0.9714, 0.9568, 0.4526, 0.1655, 0.1787, 0.5325, 0.6413, 0.1056,\n",
       "         0.0322, 0.8538, 0.2896, 0.7409, 0.8154, 0.5623, 0.8752, 0.0604, 0.5992,\n",
       "         0.4290],\n",
       "        [0.9294, 0.5790, 0.8486, 0.6915, 0.0302, 0.7753, 0.4704, 0.7915, 0.0353,\n",
       "         0.5431, 0.8824, 0.2545, 0.1992, 0.1911, 0.9492, 0.0980, 0.4411, 0.4679,\n",
       "         0.6967, 0.6692, 0.8125, 0.6599, 0.3800, 0.1168, 0.1070, 0.7325, 0.0092,\n",
       "         0.1575],\n",
       "        [0.8350, 0.2841, 0.8081, 0.3054, 0.6932, 0.8771, 0.6069, 0.2955, 0.2744,\n",
       "         0.2652, 0.1505, 0.5438, 0.8287, 0.1066, 0.4758, 0.3962, 0.5046, 0.7534,\n",
       "         0.0311, 0.0247, 0.8212, 0.0372, 0.6159, 0.6994, 0.5356, 0.6308, 0.7165,\n",
       "         0.7289],\n",
       "        [0.6552, 0.2579, 0.9879, 0.9374, 0.3016, 0.8262, 0.7586, 0.6533, 0.2979,\n",
       "         0.3318, 0.4071, 0.8912, 0.6554, 0.0281, 0.2073, 0.8790, 0.3305, 0.9111,\n",
       "         0.1930, 0.1461, 0.9581, 0.2990, 0.7662, 0.0852, 0.4389, 0.1316, 0.9670,\n",
       "         0.8758],\n",
       "        [0.3100, 0.4774, 0.1750, 0.8616, 0.4665, 0.7684, 0.6797, 0.9731, 0.7720,\n",
       "         0.1724, 0.7998, 0.5673, 0.2129, 0.4854, 0.2515, 0.7065, 0.3041, 0.3819,\n",
       "         0.9683, 0.2036, 0.1200, 0.7576, 0.3775, 0.4968, 0.4147, 0.5607, 0.1943,\n",
       "         0.1255]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=net(x.view(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3103, -2.4142, -2.2214, -2.3513, -2.2157, -2.2245, -2.2965, -2.3830,\n",
       "         -2.2388, -2.3975]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3103, -2.4142, -2.2214, -2.3513, -2.2157, -2.2245, -2.2965, -2.3830,\n",
       "         -2.2388, -2.3975]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac10d83fceb4ed9a90b0723741386d9b1d3045d81a85b27a90b8b2eecd3168c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
